{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c1cfa75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "import dill\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import logging\n",
    "import gc\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14896cb5",
   "metadata": {},
   "source": [
    "#### Представим, что у нас есть пара сырых файлов паркет по которым нужно предсказать кредитную историю (сохранил 1 рандомный файл паркет из исходной выборки), у меня все прописано в модуле dd, который сразу энкодит и сохраняет датасет, который потом скармливается в модель и получает предикты (функция из модуля dd modify_data_pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6678aac",
   "metadata": {},
   "source": [
    "#### Промежуточные шаги по типу энкодинга не включены, так как изначально обрабатываются в функции dd.modify_data(), с помощью которой тренировочный фрейм был сохранен на этапе моделирования, предикт реализуется отдельной функцией"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59b19645",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_fit() -> None:\n",
    "    ## Загружаем данные тренировочной выборки для последующего обучения моделей и выбора лучшей\n",
    "    data = pd.read_csv('train_data_for_pipe.csv', index_col=0)\n",
    "    \n",
    "    X = data.drop('flag', axis=1)\n",
    "    y = data['flag']\n",
    "    \n",
    "    del data\n",
    "    \n",
    "    numerical_features = make_column_selector(dtype_include=['int64', 'float64'])\n",
    "    categorical_features = make_column_selector(dtype_include=object)\n",
    "    \n",
    "    numerical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy=\"most_frequent\"))\n",
    "    ])\n",
    "    \n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent'))\n",
    "    ])\n",
    "    \n",
    "    path_to_save = 'pickle_model'\n",
    "    model_filename_xgb = f'{path_to_save}/XGBClassifier_cr_sc.pkl'\n",
    "    model_filename_cat = f'{path_to_save}/CatClassifier_cr_sc.pkl'\n",
    "    model_filename_lgbm = f'{path_to_save}/LGBMClassifier_cr_sc.pkl'\n",
    "\n",
    "    with open(model_filename_xgb, 'rb') as file:\n",
    "        XGBClassifier = dill.load(file)\n",
    "        \n",
    "    with open(model_filename_cat, 'rb') as file:\n",
    "        CatBoostClassifier = dill.load(file)\n",
    "        \n",
    "    with open(model_filename_lgbm, 'rb') as file:\n",
    "        LGBMClassifier = dill.load(file)\n",
    "    \n",
    "    \n",
    "    \n",
    "    models = [\n",
    "        XGBClassifier,\n",
    "        CatBoostClassifier,\n",
    "        LGBMClassifier\n",
    "    ]\n",
    "    \n",
    "    best_score = .0\n",
    "    best_pipe = None\n",
    "    \n",
    "    for model in models:\n",
    "        \n",
    "        pipe = Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "            ('classifier', model)\n",
    "        ])\n",
    "        \n",
    "        score = cross_val_score(pipe, X, y, cv=3, scoring='roc_auc')\n",
    "\n",
    "        if score.mean() > best_score:\n",
    "            best_score = score.mean()\n",
    "            best_pipe = model\n",
    "        \n",
    "    logging.info(f'Best Model: {model}, roc_auc_mean: {best_score}')\n",
    "    \n",
    "    print(f'Best Model: {model}, roc_auc_mean: {best_score}')\n",
    "        \n",
    "    best_pipe.fit(X, y)\n",
    "    \n",
    "    model_filename_save = f'{path_to_save}/best_model_ever.pkl'\n",
    "    \n",
    "    with open(model_filename_save, 'wb') as file:\n",
    "        dill.dump(best_pipe, file)\n",
    "        \n",
    "    return best_pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a323f732",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PipeLine(object):\n",
    "    \n",
    "    def __init__(self, target, path, path_to_save_model):\n",
    "        self.pipe = None\n",
    "        self.target = target\n",
    "        self.path = path\n",
    "        self.path_to_save = path_to_save_model\n",
    "        self.best_score = None\n",
    "        \n",
    "    def print_info(self):\n",
    "        print(self.target, self.path)\n",
    "        \n",
    "    def pipeline_fit(self) -> None:\n",
    "        \n",
    "        print(f'Starting fitting for {self.target} in {self.path}')\n",
    "        \n",
    "        data = pd.read_csv(self.path, index_col=0)\n",
    "        \n",
    "        X = data.drop(self.target, axis=1)\n",
    "        y = data[self.target]\n",
    "        \n",
    "        del data\n",
    "        \n",
    "        numerical_features = make_column_selector(dtype_include=['int64', 'float64'])\n",
    "        categorical_features = make_column_selector(dtype_include=object)\n",
    "        \n",
    "        model_filename_xgb = f'{self.path_to_save}/XGBClassifier_cr_sc.pkl'\n",
    "        model_filename_cat = f'{self.path_to_save}/CatClassifier_cr_sc.pkl'\n",
    "        model_filename_lgbm = f'{self.path_to_save}/LGBMClassifier_cr_sc.pkl'\n",
    "        \n",
    "        with open(model_filename_xgb, 'rb') as file:\n",
    "            XGBClassifier = dill.load(file)\n",
    "\n",
    "        with open(model_filename_cat, 'rb') as file:\n",
    "            CatBoostClassifier = dill.load(file)\n",
    "\n",
    "        with open(model_filename_lgbm, 'rb') as file:\n",
    "            LGBMClassifier = dill.load(file)\n",
    "            \n",
    "        models = [\n",
    "        XGBClassifier,\n",
    "        CatBoostClassifier,\n",
    "        LGBMClassifier]\n",
    "        \n",
    "        best_score = .0\n",
    "        best_pipe = None\n",
    "        \n",
    "        for model in models:\n",
    "            \n",
    "            pipe = Pipeline([\n",
    "                ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "                ('classifier', model)\n",
    "            ])\n",
    "            \n",
    "            score = cross_val_score(pipe, X, y, cv=3, scoring='roc_auc')\n",
    "            \n",
    "            if score.mean() > best_score:\n",
    "                best_score = score.mean()\n",
    "                best_pipe = model\n",
    "                \n",
    "        print(f'Best Model: {model}, roc_auc_mean: {best_score}')\n",
    "        \n",
    "        best_pipe = best_pipe.fit(X, y)\n",
    "        \n",
    "        self.pipe = best_pipe\n",
    "        \n",
    "        print(f'Model {model} fitting done')\n",
    "        \n",
    "        model_filename_save = f'{self.path_to_save}/best_model_ever.pkl'\n",
    "        \n",
    "        with open(model_filename_save, 'wb') as file:\n",
    "            dill.dump(best_pipe, file)\n",
    "            \n",
    "        return self.pipe\n",
    "    \n",
    "    def predict(path_to_predict_data, path_to_save, target_path, path_to_save):\n",
    "        \n",
    "        predict_data = dd.modify_data(path_to_dataset=path_to_predict_data,\n",
    "                              num_parts_to_preprocess_at_once=1,\n",
    "                              num_parts_total=3,\n",
    "                              save_to_path=path_to_save,\n",
    "                              target_path=target_path,\n",
    "                              path_to_save=path_to_save)\n",
    "        \n",
    "        predict_data.drop(['id'], axis=1, inplace=True)\n",
    "        \n",
    "        display(predict_data.head(5))\n",
    "        \n",
    "        predictions = self.pipe.predict(predict_data)\n",
    "        \n",
    "        return predictions\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac55e6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = PipeLine(target='flag', path='train_data_for_pipe.csv', path_to_save_model='pickle_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418852ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting fitting for flag in train_data_for_pipe.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.py:583: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttotal: 363ms\tremaining: 30m 13s\n",
      "1000:\ttotal: 2m 56s\tremaining: 11m 43s\n",
      "2000:\ttotal: 5m 37s\tremaining: 8m 25s\n",
      "3000:\ttotal: 7m 58s\tremaining: 5m 18s\n",
      "4000:\ttotal: 10m 14s\tremaining: 2m 33s\n",
      "4999:\ttotal: 12m 34s\tremaining: 0us\n"
     ]
    }
   ],
   "source": [
    "best_best = pipe.pipeline_fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b0f4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = best_pipe.predict(path_to_predict_data='data_for_pipe/train_data',\n",
    "                              save_to_path='data_for_pipe/preprocess_train_data',\n",
    "                              target_path='data_for_pipe/process_data',\n",
    "                              path_to_save='data_for_pipe/preprocess_train_data')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
